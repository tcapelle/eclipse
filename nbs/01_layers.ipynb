{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f61f73-8683-4638-b730-6d9174eb212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea22c98-3207-4673-8ee8-7396637f45cd",
   "metadata": {},
   "source": [
    "# Layers\n",
    "> most of them come from [fiery](https://github.com/wayveai/fiery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f4b7d-ace4-4416-a067-9d7025ef7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from eclipse_pytorch.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f80af7-bcc4-43a8-a6bd-283991737d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_activation(activation):\n",
    "    if activation == 'relu':\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif activation == 'lrelu':\n",
    "        return nn.LeakyReLU(0.1, inplace=True)\n",
    "    elif activation == 'elu':\n",
    "        return nn.ELU(inplace=True)\n",
    "    elif activation == 'tanh':\n",
    "        return nn.Tanh(inplace=True)\n",
    "    elif activation == 'none':\n",
    "        return None\n",
    "    else:\n",
    "        raise ValueError('Invalid activation {}'.format(activation))\n",
    "        \n",
    "def get_norm(norm, out_channels):\n",
    "    if norm == 'bn':\n",
    "        return nn.BatchNorm2d(out_channels)\n",
    "    elif norm == 'in':\n",
    "        return nn.InstanceNorm2d(out_channels)\n",
    "    elif norm == 'none':\n",
    "        return None\n",
    "    else:\n",
    "        raise ValueError('Invalid norm {}'.format(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158184b-c6d0-4a22-8625-f8514b1b524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"2D convolution followed by\n",
    "         - an optional normalisation (batch norm or instance norm)\n",
    "         - an optional activation (ReLU, LeakyReLU, or tanh)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels=None,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        norm='bn',\n",
    "        activation='relu',\n",
    "        bias=False,\n",
    "        transpose=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        out_channels = out_channels or in_channels\n",
    "        padding = int((kernel_size - 1) / 2)\n",
    "        self.conv = nn.Conv2d if not transpose else partial(nn.ConvTranspose2d, output_padding=1)\n",
    "        self.conv = self.conv(in_channels, out_channels, kernel_size, stride, padding=padding, bias=bias)\n",
    "        self.activation = get_activation(activation)\n",
    "        self.norm = get_norm(norm, out_channels)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        if self.norm:\n",
    "            x = self.norm(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f1349-6d9d-4a3c-8be3-92f2a9d5c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a bottleneck module with a residual connection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels=None,\n",
    "        kernel_size=3,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        upsample=False,\n",
    "        downsample=False,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._downsample = downsample\n",
    "        bottleneck_channels = int(in_channels / 2)\n",
    "        out_channels = out_channels or in_channels\n",
    "        padding_size = ((kernel_size - 1) * dilation + 1) // 2\n",
    "\n",
    "        # Define the main conv operation\n",
    "        assert dilation == 1\n",
    "        if upsample:\n",
    "            assert not downsample, 'downsample and upsample not possible simultaneously.'\n",
    "            bottleneck_conv = nn.ConvTranspose2d(\n",
    "                bottleneck_channels,\n",
    "                bottleneck_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                bias=False,\n",
    "                dilation=1,\n",
    "                stride=2,\n",
    "                output_padding=padding_size,\n",
    "                padding=padding_size,\n",
    "                groups=groups,\n",
    "            )\n",
    "        elif downsample:\n",
    "            bottleneck_conv = nn.Conv2d(\n",
    "                bottleneck_channels,\n",
    "                bottleneck_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                bias=False,\n",
    "                dilation=dilation,\n",
    "                stride=2,\n",
    "                padding=padding_size,\n",
    "                groups=groups,\n",
    "            )\n",
    "        else:\n",
    "            bottleneck_conv = nn.Conv2d(\n",
    "                bottleneck_channels,\n",
    "                bottleneck_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                bias=False,\n",
    "                dilation=dilation,\n",
    "                padding=padding_size,\n",
    "                groups=groups,\n",
    "            )\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    # First projection with 1x1 kernel\n",
    "                    ('conv_down_project', nn.Conv2d(in_channels, bottleneck_channels, kernel_size=1, bias=False)),\n",
    "                    ('abn_down_project', nn.Sequential(nn.BatchNorm2d(bottleneck_channels),\n",
    "                                                       nn.ReLU(inplace=True))),\n",
    "                    # Second conv block\n",
    "                    ('conv', bottleneck_conv),\n",
    "                    ('abn', nn.Sequential(nn.BatchNorm2d(bottleneck_channels), nn.ReLU(inplace=True))),\n",
    "                    # Final projection with 1x1 kernel\n",
    "                    ('conv_up_project', nn.Conv2d(bottleneck_channels, out_channels, kernel_size=1, bias=False)),\n",
    "                    ('abn_up_project', nn.Sequential(nn.BatchNorm2d(out_channels),\n",
    "                                                     nn.ReLU(inplace=True))),\n",
    "                    # Regulariser\n",
    "                    ('dropout', nn.Dropout2d(p=dropout)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if out_channels == in_channels and not downsample and not upsample:\n",
    "            self.projection = None\n",
    "        else:\n",
    "            projection = OrderedDict()\n",
    "            if upsample:\n",
    "                projection.update({'upsample_skip_proj': Interpolate(scale_factor=2)})\n",
    "            elif downsample:\n",
    "                projection.update({'upsample_skip_proj': nn.MaxPool2d(kernel_size=2, stride=2)})\n",
    "            projection.update(\n",
    "                {\n",
    "                    'conv_skip_proj': nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                    'bn_skip_proj': nn.BatchNorm2d(out_channels),\n",
    "                }\n",
    "            )\n",
    "            self.projection = nn.Sequential(projection)\n",
    "\n",
    "    # pylint: disable=arguments-differ\n",
    "    def forward(self, *args):\n",
    "        (x,) = args\n",
    "        x_residual = self.layers(x)\n",
    "        if self.projection is not None:\n",
    "            if self._downsample:\n",
    "                # pad h/w dimensions if they are odd to prevent shape mismatch with residual layer\n",
    "                x = nn.functional.pad(x, (0, x.shape[-1] % 2, 0, x.shape[-2] % 2), value=0)\n",
    "            return x_residual + self.projection(x)\n",
    "        return x_residual + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd71c90-9228-4a9f-9821-20328c57ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Interpolate(nn.Module):\n",
    "    def __init__(self, scale_factor: int = 2):\n",
    "        super().__init__()\n",
    "        self._interpolate = nn.functional.interpolate\n",
    "        self._scale_factor = scale_factor\n",
    "\n",
    "    # pylint: disable=arguments-differ\n",
    "    def forward(self, x):\n",
    "        return self._interpolate(x, scale_factor=self._scale_factor, mode='bilinear', align_corners=False)\n",
    "\n",
    "\n",
    "class UpsamplingConcat(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scale_factor=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners=False)\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_to_upsample, x):\n",
    "        x_to_upsample = self.upsample(x_to_upsample)\n",
    "        x_to_upsample = torch.cat([x, x_to_upsample], dim=1)\n",
    "        return self.conv(x_to_upsample)\n",
    "\n",
    "\n",
    "class UpsamplingAdd(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scale_factor=2):\n",
    "        super().__init__()\n",
    "        self.upsample_layer = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_skip):\n",
    "        x = self.upsample_layer(x)\n",
    "        return x + x_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ad863-f4b8-400b-a62e-b1d593ff28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlock(nn.Module):\n",
    "    \" A simple resnet Block\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, norm='bn', activation='relu'):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(ConvBlock(in_channels,  out_channels, kernel_size, stride, norm=norm, activation=activation),\n",
    "                                   ConvBlock(out_channels, out_channels, norm=norm, activation=activation)\n",
    "                                  )\n",
    "        id_path = [ConvBlock(in_channels, out_channels, kernel_size=1, activation='none', norm='none')]\n",
    "        self.activation = get_activation(activation)\n",
    "        if stride!=1: id_path.insert(1, nn.AvgPool2d(2, stride, ceil_mode=True))\n",
    "        self.id_path = nn.Sequential(*id_path)\n",
    "                                    \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.convs(x) + self.id_path(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd945e-757e-4d81-abee-8ba5fce5e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_block = ResBlock(64, 128, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc730d95-89a2-454b-8949-fa45879ccf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,64, 20,20)\n",
    "res_block(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568af38-4494-4fbe-aacb-6d3c5fa79e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SpatialGRU(nn.Module):\n",
    "    \"\"\"A GRU cell that takes an input tensor [BxTxCxHxW] and an optional previous state and passes a\n",
    "    convolutional gated recurrent unit over the data\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, gru_bias_init=0.0, norm='bn', activation='relu'):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru_bias_init = gru_bias_init\n",
    "\n",
    "        self.conv_update = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size=3, bias=True, padding=1)\n",
    "        self.conv_reset = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size=3, bias=True, padding=1)\n",
    "\n",
    "        self.conv_state_tilde = ConvBlock(\n",
    "            input_size + hidden_size, hidden_size, kernel_size=3, bias=False, norm=norm, activation=activation\n",
    "        )\n",
    "\n",
    "    def forward(self, x, state=None, flow=None, mode='bilinear'):\n",
    "        # pylint: disable=unused-argument, arguments-differ\n",
    "        # Check size\n",
    "        assert len(x.size()) == 5, 'Input tensor must be BxTxCxHxW.'\n",
    "        b, timesteps, c, h, w = x.size()\n",
    "        assert c == self.input_size, f'feature sizes must match, got input {c} for layer with size {self.input_size}'\n",
    "\n",
    "        # recurrent layers\n",
    "        rnn_output = []\n",
    "        rnn_state = torch.zeros(b, self.hidden_size, h, w, device=x.device) if state is None else state\n",
    "        for t in range(timesteps):\n",
    "            x_t = x[:, t]\n",
    "            if flow is not None:\n",
    "                rnn_state = warp_features(rnn_state, flow[:, t], mode=mode)\n",
    "\n",
    "            # propagate rnn state\n",
    "            rnn_state = self.gru_cell(x_t, rnn_state)\n",
    "            rnn_output.append(rnn_state)\n",
    "\n",
    "        # reshape rnn output to batch tensor\n",
    "        return torch.stack(rnn_output, dim=1)\n",
    "\n",
    "    def gru_cell(self, x, state):\n",
    "        # Compute gates\n",
    "        x_and_state = torch.cat([x, state], dim=1)\n",
    "        update_gate = self.conv_update(x_and_state)\n",
    "        reset_gate = self.conv_reset(x_and_state)\n",
    "        # Add bias to initialise gate as close to identity function\n",
    "        update_gate = torch.sigmoid(update_gate + self.gru_bias_init)\n",
    "        reset_gate = torch.sigmoid(reset_gate + self.gru_bias_init)\n",
    "\n",
    "        # Compute proposal state, activation is defined in norm_act_config (can be tanh, ReLU etc)\n",
    "        state_tilde = self.conv_state_tilde(torch.cat([x, (1.0 - reset_gate) * state], dim=1))\n",
    "\n",
    "        output = (1.0 - update_gate) * state + update_gate * state_tilde\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdb367-7794-48bc-94aa-1ba421a7c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgru = SpatialGRU(input_size=32, hidden_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cd120-755b-4783-b356-03044cb5abe3",
   "metadata": {},
   "source": [
    "without hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207186f-761b-4744-8e37-48f47101525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,3,32,8, 8)\n",
    "test_eq(sgru(x).shape, (1,3,64,8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcaa79f-6d57-4b74-b956-f9dcc3df0589",
   "metadata": {},
   "source": [
    "with hidden\n",
    "> hidden.shape = `(bs, hidden_size, h, w)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e47adc-2ce8-4cd9-86b4-433cbd47dbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,3,32,8, 8)\n",
    "hidden = torch.rand(1,64,8,8)\n",
    "# test_eq(sgru(x).shape, (1,3,64,8,8))\n",
    "\n",
    "sgru(x, hidden).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a2fe0-535a-4d51-ab22-81bcefac5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CausalConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(2, 3, 3), dilation=(1, 1, 1), bias=False):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size) == 3, 'kernel_size must be a 3-tuple.'\n",
    "        time_pad = (kernel_size[0] - 1) * dilation[0]\n",
    "        height_pad = ((kernel_size[1] - 1) * dilation[1]) // 2\n",
    "        width_pad = ((kernel_size[2] - 1) * dilation[2]) // 2\n",
    "\n",
    "        # Pad temporally on the left\n",
    "        self.pad = nn.ConstantPad3d(padding=(width_pad, width_pad, height_pad, height_pad, time_pad, 0), value=0)\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, dilation=dilation, stride=1, padding=0, bias=bias)\n",
    "        self.norm = nn.BatchNorm3d(out_channels)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        (x,) = inputs\n",
    "        x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c1b07-dcb1-444a-8372-bdd3ff9dd95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc3d = CausalConv3d(64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00cb8c1-7513-40e2-85ef-646ddd20d585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 4, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,64,4,8,8)\n",
    "cc3d(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac267c7-a4f3-47dd-a15a-04c61c82d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_1x1x1_norm_activated(in_channels, out_channels):\n",
    "    \"\"\"1x1x1 3D convolution, normalization and activation layer.\"\"\"\n",
    "    return nn.Sequential(\n",
    "        OrderedDict(\n",
    "            [\n",
    "                ('conv', nn.Conv3d(in_channels, out_channels, kernel_size=1, bias=False)),\n",
    "                ('norm', nn.BatchNorm3d(out_channels)),\n",
    "                ('activation', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318b3fd-d944-4d98-8965-88a1dd2d8d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv): Conv3d(2, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "  (norm): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1x1x1_norm_activated(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574dfd4-3891-464d-b0d6-a67466fed549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Bottleneck3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a bottleneck module with a residual connection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels=None, kernel_size=(2, 3, 3), dilation=(1, 1, 1)):\n",
    "        super().__init__()\n",
    "        bottleneck_channels = in_channels // 2\n",
    "        out_channels = out_channels or in_channels\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    # First projection with 1x1 kernel\n",
    "                    ('conv_down_project', conv_1x1x1_norm_activated(in_channels, bottleneck_channels)),\n",
    "                    # Second conv block\n",
    "                    (\n",
    "                        'conv',\n",
    "                        CausalConv3d(\n",
    "                            bottleneck_channels,\n",
    "                            bottleneck_channels,\n",
    "                            kernel_size=kernel_size,\n",
    "                            dilation=dilation,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    # Final projection with 1x1 kernel\n",
    "                    ('conv_up_project', conv_1x1x1_norm_activated(bottleneck_channels, out_channels)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if out_channels != in_channels:\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm3d(out_channels),\n",
    "            )\n",
    "        else:\n",
    "            self.projection = None\n",
    "\n",
    "    def forward(self, *args):\n",
    "        (x,) = args\n",
    "        x_residual = self.layers(x)\n",
    "        x_features = self.projection(x) if self.projection is not None else x\n",
    "        return x_residual + x_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbcf0d0-1cc2-4914-9ba0-30b99f03a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn3d = Bottleneck3D(8, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12917923-c26f-4c40-b2ee-2836d2ffb4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 4, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,8,4,8,8)\n",
    "bn3d(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3b9ac-7faa-4da6-b59b-86792e649590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PyramidSpatioTemporalPooling(nn.Module):\n",
    "    \"\"\" Spatio-temporal pyramid pooling.\n",
    "        Performs 3D average pooling followed by 1x1x1 convolution to reduce the number of channels and upsampling.\n",
    "        Setting contains a list of kernel_size: usually it is [(2, h, w), (2, h//2, w//2), (2, h//4, w//4)]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, reduction_channels, pool_sizes):\n",
    "        super().__init__()\n",
    "        self.features = []\n",
    "        for pool_size in pool_sizes:\n",
    "            assert pool_size[0] == 2, (\n",
    "                \"Time kernel should be 2 as PyTorch raises an error when\" \"padding with more than half the kernel size\"\n",
    "            )\n",
    "            stride = (1, *pool_size[1:])\n",
    "            padding = (pool_size[0] - 1, 0, 0)\n",
    "            self.features.append(\n",
    "                nn.Sequential(\n",
    "                    OrderedDict(\n",
    "                        [\n",
    "                            # Pad the input tensor but do not take into account zero padding into the average.\n",
    "                            (\n",
    "                                'avgpool',\n",
    "                                torch.nn.AvgPool3d(\n",
    "                                    kernel_size=pool_size, stride=stride, padding=padding, count_include_pad=False\n",
    "                                ),\n",
    "                            ),\n",
    "                            ('conv_bn_relu', conv_1x1x1_norm_activated(in_channels, reduction_channels)),\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        self.features = nn.ModuleList(self.features)\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        (x,) = inputs\n",
    "        b, _, t, h, w = x.shape\n",
    "        # Do not include current tensor when concatenating\n",
    "        out = []\n",
    "        for f in self.features:\n",
    "            # Remove unnecessary padded values (time dimension) on the right\n",
    "            x_pool = f(x)[:, :, :-1].contiguous()\n",
    "            c = x_pool.shape[1]\n",
    "            x_pool = nn.functional.interpolate(\n",
    "                x_pool.view(b * t, c, *x_pool.shape[-2:]), (h, w), mode='bilinear', align_corners=False\n",
    "            )\n",
    "            x_pool = x_pool.view(b, c, t, h, w)\n",
    "            out.append(x_pool)\n",
    "        out = torch.cat(out, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45902f68-7d7f-4935-ac97-00e332ef9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = (64,64)\n",
    "ptp = PyramidSpatioTemporalPooling(12, 12, [(2, h, w), (2, h//2, w//2), (2, h//4, w//4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0db71a-dfef-4389-bc9c-483adc060008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 36, 4, 64, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,12,4,64,64)\n",
    "\n",
    "#the output is concatenated...\n",
    "ptp(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575bf79-6718-4a70-90ed-985b79fea483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TemporalBlock(nn.Module):\n",
    "    \"\"\" Temporal block with the following layers:\n",
    "        - 2x3x3, 1x3x3, spatio-temporal pyramid pooling\n",
    "        - dropout\n",
    "        - skip connection.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels=None, use_pyramid_pooling=False, pool_sizes=None):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.half_channels = in_channels // 2\n",
    "        self.out_channels = out_channels or self.in_channels\n",
    "        self.kernels = [(2, 3, 3), (1, 3, 3)]\n",
    "\n",
    "        # Flag for spatio-temporal pyramid pooling\n",
    "        self.use_pyramid_pooling = use_pyramid_pooling\n",
    "\n",
    "        # 3 convolution paths: 2x3x3, 1x3x3, 1x1x1\n",
    "        self.convolution_paths = []\n",
    "        for kernel_size in self.kernels:\n",
    "            self.convolution_paths.append(\n",
    "                nn.Sequential(\n",
    "                    conv_1x1x1_norm_activated(self.in_channels, self.half_channels),\n",
    "                    CausalConv3d(self.half_channels, self.half_channels, kernel_size=kernel_size),\n",
    "                )\n",
    "            )\n",
    "        self.convolution_paths.append(conv_1x1x1_norm_activated(self.in_channels, self.half_channels))\n",
    "        self.convolution_paths = nn.ModuleList(self.convolution_paths)\n",
    "\n",
    "        agg_in_channels = len(self.convolution_paths) * self.half_channels\n",
    "\n",
    "        if self.use_pyramid_pooling:\n",
    "            assert pool_sizes is not None, \"setting must contain the list of kernel_size, but is None.\"\n",
    "            reduction_channels = self.in_channels // 3\n",
    "            self.pyramid_pooling = PyramidSpatioTemporalPooling(self.in_channels, reduction_channels, pool_sizes)\n",
    "            agg_in_channels += len(pool_sizes) * reduction_channels\n",
    "\n",
    "        # Feature aggregation\n",
    "        self.aggregation = nn.Sequential(\n",
    "            conv_1x1x1_norm_activated(agg_in_channels, self.out_channels),)\n",
    "\n",
    "        if self.out_channels != self.in_channels:\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.Conv3d(self.in_channels, self.out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm3d(self.out_channels),\n",
    "            )\n",
    "        else:\n",
    "            self.projection = None\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        (x,) = inputs\n",
    "        x_paths = []\n",
    "        for conv in self.convolution_paths:\n",
    "            x_paths.append(conv(x))\n",
    "        x_residual = torch.cat(x_paths, dim=1)\n",
    "        if self.use_pyramid_pooling:\n",
    "            x_pool = self.pyramid_pooling(x)\n",
    "            x_residual = torch.cat([x_residual, x_pool], dim=1)\n",
    "        x_residual = self.aggregation(x_residual)\n",
    "\n",
    "        if self.out_channels != self.in_channels:\n",
    "            x = self.projection(x)\n",
    "        x = x + x_residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f0475-0c44-4b90-83bf-6869c24e105e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = TemporalBlock(4,8)\n",
    "\n",
    "x = torch.rand(1,4,4,64,64)\n",
    "\n",
    "tb(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f671904-4256-48d5-8787-72556d225456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FuturePrediction(torch.nn.Module):\n",
    "    def __init__(self, in_channels, latent_dim, n_gru_blocks=3, n_res_layers=3):\n",
    "        super().__init__()\n",
    "        self.n_gru_blocks = n_gru_blocks\n",
    "\n",
    "        # Convolutional recurrent model with z_t as an initial hidden state and inputs the sample\n",
    "        # from the probabilistic model. The architecture of the model is:\n",
    "        # [Spatial GRU - [Bottleneck] x n_res_layers] x n_gru_blocks\n",
    "        self.spatial_grus = []\n",
    "        self.res_blocks = []\n",
    "\n",
    "        for i in range(self.n_gru_blocks):\n",
    "            gru_in_channels = latent_dim if i == 0 else in_channels\n",
    "            self.spatial_grus.append(SpatialGRU(gru_in_channels, in_channels))\n",
    "            self.res_blocks.append(torch.nn.Sequential(*[Bottleneck(in_channels)\n",
    "                                                         for _ in range(n_res_layers)]))\n",
    "\n",
    "        self.spatial_grus = torch.nn.ModuleList(self.spatial_grus)\n",
    "        self.res_blocks = torch.nn.ModuleList(self.res_blocks)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        # x has shape (b, n_future, c, h, w), hidden_state (b, c, h, w)\n",
    "        for i in range(self.n_gru_blocks):\n",
    "            x = self.spatial_grus[i](x, hidden_state, flow=None)\n",
    "            b, n_future, c, h, w = x.shape\n",
    "\n",
    "            x = self.res_blocks[i](x.view(b * n_future, c, h, w))\n",
    "            x = x.view(b, n_future, c, h, w)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce0e2ce-a862-4631-b5f7-a6b2c9928415",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = FuturePrediction(32, 32, 4, 4)\n",
    "\n",
    "x = torch.rand(1,4, 32, 64, 64)\n",
    "hidden = torch.rand(1,32,64,64)\n",
    "test_eq(fp(x, hidden).shape, x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542aa109-21e9-48b8-a87a-e4bbd5f59b8d",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c520b5-d666-4ebb-a9c0-02992b822b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_model.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
