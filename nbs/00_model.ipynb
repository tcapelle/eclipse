{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "> from the paper from [Paletta et al](https://arxiv.org/pdf/2104.12419v1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to implement as close as possible the architecture from the paper `ECLIPSE : Envisioning Cloud Induced Perturbations in Solar Energy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](../images/eclipse_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from eclipse_pytorch.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spatial Downsampler\n",
    "> A resnet encoder to get image features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could use any spatial downsampler as you want, but the paper states a simple resnet arch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export\n",
    "class SpatialDownsampler(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBlock(in_channels, 64, kernel_size=7, stride=1)\n",
    "        self.blocks = nn.Sequential(ResBlock(64, 64, kernel_size=3, stride=2), \n",
    "                                    ResBlock(64, 128, kernel_size=3, stride=2), \n",
    "                                    ResBlock(128,256, kernel_size=3, stride=2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.blocks(self.conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SpatialDownsampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 4, 32, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [torch.rand(1, 3, 256, 256) for _ in range(4)]\n",
    "features = torch.stack([sd(image) for image in images], dim=2)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TemporalBlock(256, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 4, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_encoded = te(features)\n",
    "temp_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Future State Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = FuturePrediction(128, 128, n_gru_blocks=4, n_res_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128, 32, 32])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = torch.rand(1, 128, 32, 32)\n",
    "\n",
    "fp(temp_encoded.permute(0,2,1,3,4), hidden).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4A. Segmentation Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = Bottleneck(256, 128, upsample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 4, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 64, 64])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,256,32,32)\n",
    "bn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Upsampler(nn.Module):\n",
    "    def __init__(self, sizes=[256,128,64], n_out=3):\n",
    "        super().__init__()\n",
    "        zsizes = zip(sizes[:-1], sizes[1:])\n",
    "        self.convs = nn.Sequential(*[Bottleneck(si, sf, upsample=True) for si,sf in zsizes], \n",
    "                                   Bottleneck(sizes[-1], sizes[-1], upsample=True), \n",
    "                                   ConvBlock(sizes[-1], n_out, kernel_size=1, activation='none'))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.convs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = Upsampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4B. Irradiance Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IrradianceModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(ConvBlock(128, 64), \n",
    "                                   ConvBlock(64, 64),\n",
    "                                   nn.AdaptiveMaxPool2d(1)\n",
    "                                  )\n",
    "        self.linear = nn.Sequential(nn.Flatten(), \n",
    "                                    nn.BatchNorm1d(64),\n",
    "                                    nn.Linear(64, 1)\n",
    "                                   )\n",
    "    def forward(self, x):\n",
    "        return self.linear(self.convs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = IrradianceModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 128, 32, 32)\n",
    "im(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything Together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.new_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eclipse(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in, horizon=5):\n",
    "        self.horizon = horizon\n",
    "        self.spatial_downsampler = SpatialDownsampler(n_in)\n",
    "        self.temporal_encoder = TemporalBlock(256, 128)\n",
    "        self.future_state = FuturePrediction(128, 128, n_gru_blocks=4, n_res_layers=4)\n",
    "        self.upsampler = Upsampler()\n",
    "        self.irradiance = IrradianceModule()\n",
    "    \n",
    "    def set_hidden(x):\n",
    "        bs, ch, t, h, w = x.shape\n",
    "        self.hidden_state = x.new_zeros(bs, ch, h, w)\n",
    "        \n",
    "    def forward(imgs):\n",
    "        down_imgs = torch.stack([self.spatial_downsampler(img) for img in imgs], dim=2)\n",
    "        te_imgs = self.temporal_encoder(down_imgs)\n",
    "        \n",
    "        preds = {'masks': [], 'irradiance': []}\n",
    "        self.set_hidden(te_imgs)\n",
    "        for _ in range(self.horizon):\n",
    "            self.future_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_model.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
