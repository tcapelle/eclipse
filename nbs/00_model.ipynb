{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "> from the paper from [Paletta et al](https://arxiv.org/pdf/2104.12419v1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to implement as close as possible the architecture from the paper `ECLIPSE : Envisioning Cloud Induced Perturbations in Solar Energy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](images/eclipse_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from eclipse_pytorch.imports import *\n",
    "from eclipse_pytorch.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spatial Downsampler\n",
    "> A resnet encoder to get image features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could use any spatial downsampler as you want, but the paper states a simple resnet arch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SpatialDownsampler(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBlock(in_channels, 64, kernel_size=7, stride=1)\n",
    "        self.blocks = nn.Sequential(ResBlock(64, 64, kernel_size=3, stride=2), \n",
    "                                    ResBlock(64, 128, kernel_size=3, stride=2), \n",
    "                                    ResBlock(128,256, kernel_size=3, stride=2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.blocks(self.conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SpatialDownsampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 4, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [torch.rand(1, 3, 64, 64) for _ in range(4)]\n",
    "features = torch.stack([sd(image) for image in images], dim=2)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TemporalBlock(256, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 4, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_encoded = te(features)\n",
    "temp_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Future State Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = FuturePrediction(128, 128, n_gru_blocks=4, n_res_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = torch.rand(1, 128, 8, 8)\n",
    "x = torch.rand(1, 4, 128, 8, 8)\n",
    "fp(x, hidden).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4A. Segmentation Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck(\n",
       "  (layers): Sequential(\n",
       "    (conv_down_project): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (abn_down_project): Sequential(\n",
       "      (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (abn): Sequential(\n",
       "      (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv_up_project): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (abn_up_project): Sequential(\n",
       "      (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.0, inplace=False)\n",
       "  )\n",
       "  (projection): Sequential(\n",
       "    (upsample_skip_proj): Interpolate()\n",
       "    (conv_skip_proj): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn_skip_proj): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = Bottleneck(256, 128, upsample=True)\n",
    "bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 4, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 64, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,256,32,32)\n",
    "bn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Upsampler(nn.Module):\n",
    "    def __init__(self, sizes=[128,128,64], n_out=3):\n",
    "        super().__init__()\n",
    "        zsizes = zip(sizes[:-1], sizes[1:])\n",
    "        self.convs = nn.Sequential(*[Bottleneck(si, sf, upsample=True) for si,sf in zsizes], \n",
    "                                   Bottleneck(sizes[-1], sizes[-1], upsample=True), \n",
    "                                   ConvBlock(sizes[-1], n_out, kernel_size=1, activation='none'))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.convs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us = Upsampler()\n",
    "\n",
    "x = torch.rand(1,128,32,32)\n",
    "us(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4B. Irradiance Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IrradianceModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(ConvBlock(128, 64), \n",
    "                                   ConvBlock(64, 64),\n",
    "                                   nn.AdaptiveMaxPool2d(1)\n",
    "                                  )\n",
    "        self.linear = nn.Sequential(nn.Flatten(), \n",
    "                                    nn.BatchNorm1d(64),\n",
    "                                    nn.Linear(64, 1)\n",
    "                                   )\n",
    "    def forward(self, x):\n",
    "        return self.linear(self.convs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = IrradianceModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 128, 32, 32)\n",
    "im(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything Together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Eclipse(nn.Module):\n",
    "    \"\"\"Not very parametric\"\"\"\n",
    "    def __init__(self, n_in=3, n_out=4, horizon=5, debug=False):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "        self.spatial_downsampler = SpatialDownsampler(n_in)\n",
    "        self.temporal_model = TemporalBlock(256, 128)\n",
    "        self.future_prediction = FuturePrediction(128, 128, n_gru_blocks=4, n_res_layers=4)\n",
    "        self.upsampler = Upsampler(n_out=n_out)\n",
    "        self.irradiance = IrradianceModule()\n",
    "    \n",
    "    def zero_hidden(self, x, horizon):\n",
    "        bs, ch, h, w = x.shape\n",
    "        return x.new_zeros(bs, horizon, ch, h, w)\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        x = torch.stack([self.spatial_downsampler(img) for img in imgs], dim=2)\n",
    "        \n",
    "        #encode temporal model\n",
    "        states = self.temporal_model(x).permute(0, 2, 1, 3, 4).contiguous()\n",
    "        if self.debug: print(f'{states.shape=}')\n",
    "        \n",
    "        #get hidden state\n",
    "        present_state = states[:, -1:]\n",
    "        if self.debug: print(f'{present_state.shape=}')\n",
    "        \n",
    "        \n",
    "        # Prepare future prediction input\n",
    "        hidden_state = present_state.squeeze()\n",
    "        if self.debug: print(f'{hidden_state.shape=}')\n",
    "        \n",
    "        future_prediction_input = self.zero_hidden(hidden_state, self.horizon)\n",
    "        \n",
    "        # Recursively predict future states\n",
    "        future_states = self.future_prediction(future_prediction_input, hidden_state)\n",
    "\n",
    "        # Concatenate present state\n",
    "        future_states = torch.cat([present_state, future_states], dim=1)\n",
    "        if self.debug: print(f'{future_states.shape=}')\n",
    "        \n",
    "        #decode outputs\n",
    "        preds = {'masks': [], 'irradiance': []}\n",
    "        for state in future_states.unbind(dim=1):\n",
    "            preds['masks'].append(self.upsampler(state))\n",
    "            preds['irradiance'].append(self.irradiance(state))\n",
    "        return preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse = Eclipse(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states.shape=torch.Size([2, 4, 128, 16, 16])\n",
      "present_state.shape=torch.Size([2, 1, 128, 16, 16])\n",
      "hidden_state.shape=torch.Size([2, 128, 16, 16])\n",
      "future_states.shape=torch.Size([2, 6, 128, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 128, 128]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = eclipse([torch.rand(2, 3, 128, 128) for _ in range(4)])\n",
    "\n",
    "preds['masks'][0].shape, preds['irradiance'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_model.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
