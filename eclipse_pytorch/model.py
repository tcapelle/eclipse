# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_model.ipynb (unless otherwise specified).

__all__ = ['SpatialDownsampler', 'TemporalModel', 'Upsampler', 'IrradianceModule', 'Eclipse']

# Cell
from .imports import *
from .layers import *

# Cell
class SpatialDownsampler(nn.Module):

    def __init__(self, in_channels=3):
        super().__init__()
        self.conv1 = ConvBlock(in_channels, 64, kernel_size=7, stride=1)
        self.blocks = nn.Sequential(ResBlock(64, 64, kernel_size=3, stride=2),
                                    ResBlock(64, 128, kernel_size=3, stride=2),
                                    ResBlock(128,256, kernel_size=3, stride=2))

    def forward(self, x):
        return self.blocks(self.conv1(x))

# Cell
class TemporalModel(nn.Module):
    def __init__(
            self, in_channels, receptive_field, input_shape, start_out_channels=64, extra_in_channels=0,
            n_spatial_layers_between_temporal_layers=0, use_pyramid_pooling=True):
        super().__init__()
        self.receptive_field = receptive_field
        n_temporal_layers = receptive_field - 1

        h, w = input_shape
        modules = []

        block_in_channels = in_channels
        block_out_channels = start_out_channels

        for _ in range(n_temporal_layers):
            if use_pyramid_pooling:
                use_pyramid_pooling = True
                pool_sizes = [(2, h, w)]
            else:
                use_pyramid_pooling = False
                pool_sizes = None
            temporal = TemporalBlock(
                block_in_channels,
                block_out_channels,
                use_pyramid_pooling=use_pyramid_pooling,
                pool_sizes=pool_sizes,
            )
            spatial = [
                Bottleneck3D(block_out_channels, block_out_channels, kernel_size=(1, 3, 3))
                for _ in range(n_spatial_layers_between_temporal_layers)
            ]
            temporal_spatial_layers = nn.Sequential(temporal, *spatial)
            modules.extend(temporal_spatial_layers)

            block_in_channels = block_out_channels
            block_out_channels += extra_in_channels

        self.out_channels = block_in_channels

        self.model = nn.Sequential(*modules)

    def forward(self, x):
        # Reshape input tensor to (batch, C, time, H, W)
        x = x.permute(0, 2, 1, 3, 4)
        x = self.model(x)
        x = x.permute(0, 2, 1, 3, 4).contiguous()
        return x[:, (self.receptive_field - 1):]

# Cell
class Upsampler(nn.Module):
    def __init__(self, sizes=[128,128,64], n_out=3):
        super().__init__()
        zsizes = zip(sizes[:-1], sizes[1:])
        self.convs = nn.Sequential(*[Bottleneck(si, sf, upsample=True) for si,sf in zsizes],
                                   Bottleneck(sizes[-1], sizes[-1], upsample=True),
                                   ConvBlock(sizes[-1], n_out, kernel_size=1, activation=None))

    def forward(self, x):
        return self.convs(x)

# Cell
class IrradianceModule(nn.Module):
    def __init__(self):
        super().__init__()
        self.convs = nn.Sequential(ConvBlock(128, 64),
                                   ConvBlock(64, 64),
                                   nn.AdaptiveMaxPool2d(1)
                                  )
        self.linear = nn.Sequential(nn.Flatten(),
                                    nn.BatchNorm1d(64),
                                    nn.Linear(64, 1)
                                   )
    def forward(self, x):
        return self.linear(self.convs(x))

# Cell
class Eclipse(nn.Module):
    """Not very parametric"""
    def __init__(self, n_in=3, n_out=4, horizon=5, img_size=(128, 128), debug=False):
        super().__init__()
        store_attr()
        self.spatial_downsampler = SpatialDownsampler(n_in)
        self.temporal_model = TemporalModel(256, 3, input_shape=(img_size[0]//8, img_size[1]//8), start_out_channels=128)
        self.future_prediction = FuturePrediction(128, 128, n_gru_blocks=4, n_res_layers=4)
        self.upsampler = Upsampler(n_out=n_out)
        self.irradiance = IrradianceModule()

    def zero_hidden(self, x, horizon):
        bs, ch, h, w = x.shape
        return x.new_zeros(bs, horizon, ch, h, w)

    def forward(self, imgs):
        x = torch.stack([self.spatial_downsampler(img) for img in imgs], dim=1)

        #encode temporal model
        states = self.temporal_model(x)
        if self.debug: print(f'{states.shape=}')

        #get hidden state
        present_state = states[:, -1:]
        if self.debug: print(f'{present_state.shape=}')


        # Prepare future prediction input
        hidden_state = present_state.squeeze()
        if self.debug: print(f'{hidden_state.shape=}')

        future_prediction_input = self.zero_hidden(hidden_state, self.horizon)

        # Recursively predict future states
        future_states = self.future_prediction(future_prediction_input, hidden_state)

        # Concatenate present state
        future_states = torch.cat([present_state, future_states], dim=1)
        if self.debug: print(f'{future_states.shape=}')

        #decode outputs
        masks, irradiances = [], []

        for state in future_states.unbind(dim=1):
            masks.append(self.upsampler(state))
            irradiances.append(self.irradiance(state))
        return {'masks': masks, 'irradiances': torch.cat(irradiances, dim=-1)}
